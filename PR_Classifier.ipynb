{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "\n",
    "from helper_methods import *\n",
    "\n",
    "from main import create_model\n",
    "\n",
    "# define path to glove and snli files\n",
    "path = \"../Project/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\Anaconda3\\envs\\gameAI\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Danie\\Anaconda3\\envs\\gameAI\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "snli_train = pd.read_csv(path+'snli_1.0/snli_1.0_train.txt', sep=\"\\\\t\")\n",
    "snli_test = pd.read_csv(path+'snli_1.0/snli_1.0_test.txt', sep=\"\\\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane. A person is training his horse for a competition. neutral\n",
      "A person on a horse jumps over a broken down airplane. A person is at a diner, ordering an omelette. contradiction\n",
      "A person on a horse jumps over a broken down airplane. A person is outdoors, on a horse. entailment\n"
     ]
    }
   ],
   "source": [
    "print(snli_train['sentence1'][0],snli_train['sentence2'][0], snli_train['gold_label'][0])\n",
    "print(snli_train['sentence1'][1],snli_train['sentence2'][1], snli_train['gold_label'][1])\n",
    "print(snli_train['sentence1'][2],snli_train['sentence2'][2], snli_train['gold_label'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       183416\n",
       "contradiction    183187\n",
       "neutral          182764\n",
       "Name: gold_label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter and rename the important columns\n",
    "train_df = snli_train.filter(['sentence1','sentence2','gold_label'], axis=1)\n",
    "test_df = snli_test.filter(['sentence1','sentence2','gold_label'], axis=1)\n",
    "train_df = train_df.rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})\n",
    "test_df = test_df.rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})\n",
    "\n",
    "# exclude sentences which could not be categorised\n",
    "train_df = train_df[train_df['gold_label'] != \"-\"]\n",
    "test_df = test_df[test_df['gold_label'] != \"-\"]\n",
    "\n",
    "train_df['gold_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = get_glove_embedding(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane.\n",
      "[1, 56, 5, 1, 197, 191, 68, 1, 1762, 36, 877]\n",
      "the max sentence length is: 78\n",
      "18490\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  59 132   4 666  16  94]\n"
     ]
    }
   ],
   "source": [
    "pad_seq_prem, embedding_matrix_prem, vocab_size_prem = get_embedding_matrix(train_df['premise'], embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person is training his horse for a competition.\n",
      "[1, 27, 3, 821, 16, 162, 20, 1, 275]\n",
      "the max sentence length is: 56\n",
      "30904\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  22   4  40 705]\n"
     ]
    }
   ],
   "source": [
    "pad_seq_hyp, embedding_matrix_hyp, vocab_size_hyp = get_embedding_matrix(train_df['hypothesis'], embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['contradiction', 'entailment', 'neutral'], dtype=object)]\n",
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "enc_gold_label = encode_labels(train_df['gold_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Embeddings(Use sum of word embeddings to get sentence embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embs = baseline_sum_sentence_embeddings(pad_seq_prem, embedding_matrix_prem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embs_hyp = baseline_sum_sentence_embeddings(pad_seq_hyp, embedding_matrix_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          30100       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          30100       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200)          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          10100       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          10100       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3)            303         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 100,803\n",
      "Trainable params: 100,803\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta',loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 1.1271 - accuracy: 0.3444 - val_loss: 1.1064 - val_accuracy: 0.3639\n",
      "Epoch 2/100\n",
      "1717/1717 [==============================] - 8s 4ms/step - loss: 1.0931 - accuracy: 0.3857 - val_loss: 1.0821 - val_accuracy: 0.4039\n",
      "Epoch 3/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 1.0732 - accuracy: 0.4199 - val_loss: 1.0656 - val_accuracy: 0.4337\n",
      "Epoch 4/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 1.0583 - accuracy: 0.4440 - val_loss: 1.0523 - val_accuracy: 0.4535\n",
      "Epoch 5/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 1.0461 - accuracy: 0.4603 - val_loss: 1.0411 - val_accuracy: 0.4668\n",
      "Epoch 6/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 1.0356 - accuracy: 0.4726 - val_loss: 1.0315 - val_accuracy: 0.4767\n",
      "Epoch 7/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 1.0268 - accuracy: 0.4814 - val_loss: 1.0233 - val_accuracy: 0.4843\n",
      "Epoch 8/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 1.0193 - accuracy: 0.4885 - val_loss: 1.0164 - val_accuracy: 0.4906\n",
      "Epoch 9/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 1.0129 - accuracy: 0.4941 - val_loss: 1.0105 - val_accuracy: 0.4966\n",
      "Epoch 10/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 1.0073 - accuracy: 0.4989 - val_loss: 1.0053 - val_accuracy: 0.5008\n",
      "Epoch 11/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 1.0025 - accuracy: 0.5031 - val_loss: 1.0007 - val_accuracy: 0.5045\n",
      "Epoch 12/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9982 - accuracy: 0.5069 - val_loss: 0.9965 - val_accuracy: 0.5086\n",
      "Epoch 13/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9943 - accuracy: 0.5103 - val_loss: 0.9928 - val_accuracy: 0.5118\n",
      "Epoch 14/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9908 - accuracy: 0.5133 - val_loss: 0.9894 - val_accuracy: 0.5148\n",
      "Epoch 15/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9875 - accuracy: 0.5163 - val_loss: 0.9861 - val_accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9844 - accuracy: 0.5190 - val_loss: 0.9831 - val_accuracy: 0.5195\n",
      "Epoch 17/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9815 - accuracy: 0.5213 - val_loss: 0.9803 - val_accuracy: 0.5217\n",
      "Epoch 18/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9788 - accuracy: 0.5238 - val_loss: 0.9777 - val_accuracy: 0.5236\n",
      "Epoch 19/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9763 - accuracy: 0.5254 - val_loss: 0.9751 - val_accuracy: 0.5258\n",
      "Epoch 20/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9739 - accuracy: 0.5276 - val_loss: 0.9727 - val_accuracy: 0.5279\n",
      "Epoch 21/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9715 - accuracy: 0.5295 - val_loss: 0.9705 - val_accuracy: 0.5296\n",
      "Epoch 22/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9693 - accuracy: 0.5310 - val_loss: 0.9683 - val_accuracy: 0.5309\n",
      "Epoch 23/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9672 - accuracy: 0.5325 - val_loss: 0.9662 - val_accuracy: 0.5325\n",
      "Epoch 24/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9652 - accuracy: 0.5342 - val_loss: 0.9642 - val_accuracy: 0.5340\n",
      "Epoch 25/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9633 - accuracy: 0.5356 - val_loss: 0.9623 - val_accuracy: 0.5357\n",
      "Epoch 26/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9614 - accuracy: 0.5370 - val_loss: 0.9604 - val_accuracy: 0.5373\n",
      "Epoch 27/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9596 - accuracy: 0.5384 - val_loss: 0.9586 - val_accuracy: 0.5385\n",
      "Epoch 28/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9578 - accuracy: 0.5395 - val_loss: 0.9569 - val_accuracy: 0.5399\n",
      "Epoch 29/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9562 - accuracy: 0.5408 - val_loss: 0.9553 - val_accuracy: 0.5412\n",
      "Epoch 30/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9546 - accuracy: 0.5421 - val_loss: 0.9537 - val_accuracy: 0.5423\n",
      "Epoch 31/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9530 - accuracy: 0.5429 - val_loss: 0.9522 - val_accuracy: 0.5435\n",
      "Epoch 32/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9515 - accuracy: 0.5442 - val_loss: 0.9506 - val_accuracy: 0.5452\n",
      "Epoch 33/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9500 - accuracy: 0.5452 - val_loss: 0.9493 - val_accuracy: 0.5458\n",
      "Epoch 34/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9486 - accuracy: 0.5462 - val_loss: 0.9478 - val_accuracy: 0.5470\n",
      "Epoch 35/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9472 - accuracy: 0.5472 - val_loss: 0.9464 - val_accuracy: 0.5481\n",
      "Epoch 36/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9459 - accuracy: 0.5480 - val_loss: 0.9451 - val_accuracy: 0.5487\n",
      "Epoch 37/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9446 - accuracy: 0.5491 - val_loss: 0.9438 - val_accuracy: 0.5498\n",
      "Epoch 38/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9433 - accuracy: 0.5501 - val_loss: 0.9426 - val_accuracy: 0.5505\n",
      "Epoch 39/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9420 - accuracy: 0.5509 - val_loss: 0.9413 - val_accuracy: 0.5517\n",
      "Epoch 40/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9408 - accuracy: 0.5518 - val_loss: 0.9401 - val_accuracy: 0.5526\n",
      "Epoch 41/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9397 - accuracy: 0.5526 - val_loss: 0.9390 - val_accuracy: 0.5534\n",
      "Epoch 42/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9385 - accuracy: 0.5532 - val_loss: 0.9378 - val_accuracy: 0.5543\n",
      "Epoch 43/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9374 - accuracy: 0.5541 - val_loss: 0.9367 - val_accuracy: 0.5548\n",
      "Epoch 44/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9363 - accuracy: 0.5549 - val_loss: 0.9357 - val_accuracy: 0.5557\n",
      "Epoch 45/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9352 - accuracy: 0.5557 - val_loss: 0.9346 - val_accuracy: 0.5561\n",
      "Epoch 46/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9342 - accuracy: 0.5563 - val_loss: 0.9336 - val_accuracy: 0.5570\n",
      "Epoch 47/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9331 - accuracy: 0.5571 - val_loss: 0.9326 - val_accuracy: 0.5578\n",
      "Epoch 48/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9321 - accuracy: 0.5581 - val_loss: 0.9316 - val_accuracy: 0.5584\n",
      "Epoch 49/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9311 - accuracy: 0.5586 - val_loss: 0.9306 - val_accuracy: 0.5591\n",
      "Epoch 50/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9302 - accuracy: 0.5593 - val_loss: 0.9297 - val_accuracy: 0.5603\n",
      "Epoch 51/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9292 - accuracy: 0.5599 - val_loss: 0.9288 - val_accuracy: 0.5607\n",
      "Epoch 52/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9282 - accuracy: 0.5605 - val_loss: 0.9279 - val_accuracy: 0.5612\n",
      "Epoch 53/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9273 - accuracy: 0.5613 - val_loss: 0.9270 - val_accuracy: 0.5619\n",
      "Epoch 54/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9264 - accuracy: 0.5618 - val_loss: 0.9261 - val_accuracy: 0.5630\n",
      "Epoch 55/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9255 - accuracy: 0.5626 - val_loss: 0.9252 - val_accuracy: 0.5633\n",
      "Epoch 56/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9247 - accuracy: 0.5631 - val_loss: 0.9244 - val_accuracy: 0.5640\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9238 - accuracy: 0.5638 - val_loss: 0.9236 - val_accuracy: 0.5644\n",
      "Epoch 58/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9229 - accuracy: 0.5644 - val_loss: 0.9227 - val_accuracy: 0.5655\n",
      "Epoch 59/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9221 - accuracy: 0.5650 - val_loss: 0.9219 - val_accuracy: 0.5656\n",
      "Epoch 60/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9213 - accuracy: 0.5657 - val_loss: 0.9211 - val_accuracy: 0.5665\n",
      "Epoch 61/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9205 - accuracy: 0.5663 - val_loss: 0.9203 - val_accuracy: 0.5673\n",
      "Epoch 62/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9196 - accuracy: 0.5668 - val_loss: 0.9195 - val_accuracy: 0.5677\n",
      "Epoch 63/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9188 - accuracy: 0.5674 - val_loss: 0.9188 - val_accuracy: 0.5679\n",
      "Epoch 64/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9181 - accuracy: 0.5679 - val_loss: 0.9180 - val_accuracy: 0.5684\n",
      "Epoch 65/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9173 - accuracy: 0.5686 - val_loss: 0.9172 - val_accuracy: 0.5690\n",
      "Epoch 66/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9165 - accuracy: 0.5692 - val_loss: 0.9165 - val_accuracy: 0.5699\n",
      "Epoch 67/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9157 - accuracy: 0.5697 - val_loss: 0.9158 - val_accuracy: 0.5702\n",
      "Epoch 68/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9150 - accuracy: 0.5701 - val_loss: 0.9151 - val_accuracy: 0.5708\n",
      "Epoch 69/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9142 - accuracy: 0.5707 - val_loss: 0.9143 - val_accuracy: 0.5712\n",
      "Epoch 70/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9135 - accuracy: 0.5714 - val_loss: 0.9136 - val_accuracy: 0.5716\n",
      "Epoch 71/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9128 - accuracy: 0.5716 - val_loss: 0.9129 - val_accuracy: 0.5720\n",
      "Epoch 72/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9120 - accuracy: 0.5722 - val_loss: 0.9122 - val_accuracy: 0.5724\n",
      "Epoch 73/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9113 - accuracy: 0.5727 - val_loss: 0.9116 - val_accuracy: 0.5729\n",
      "Epoch 74/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9106 - accuracy: 0.5734 - val_loss: 0.9109 - val_accuracy: 0.5733\n",
      "Epoch 75/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9099 - accuracy: 0.5737 - val_loss: 0.9102 - val_accuracy: 0.5739\n",
      "Epoch 76/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9092 - accuracy: 0.5741 - val_loss: 0.9095 - val_accuracy: 0.5745\n",
      "Epoch 77/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9085 - accuracy: 0.5748 - val_loss: 0.9089 - val_accuracy: 0.5749\n",
      "Epoch 78/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9078 - accuracy: 0.5752 - val_loss: 0.9082 - val_accuracy: 0.5753\n",
      "Epoch 79/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9071 - accuracy: 0.5756 - val_loss: 0.9076 - val_accuracy: 0.5757\n",
      "Epoch 80/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9064 - accuracy: 0.5762 - val_loss: 0.9069 - val_accuracy: 0.5761\n",
      "Epoch 81/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9057 - accuracy: 0.5766 - val_loss: 0.9063 - val_accuracy: 0.5765\n",
      "Epoch 82/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9050 - accuracy: 0.5770 - val_loss: 0.9056 - val_accuracy: 0.5769\n",
      "Epoch 83/100\n",
      "1717/1717 [==============================] - 10s 6ms/step - loss: 0.9044 - accuracy: 0.5774 - val_loss: 0.9049 - val_accuracy: 0.5771\n",
      "Epoch 84/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.9037 - accuracy: 0.5780 - val_loss: 0.9043 - val_accuracy: 0.5777\n",
      "Epoch 85/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9031 - accuracy: 0.5784 - val_loss: 0.9037 - val_accuracy: 0.5779\n",
      "Epoch 86/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9024 - accuracy: 0.5788 - val_loss: 0.9031 - val_accuracy: 0.5787\n",
      "Epoch 87/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9017 - accuracy: 0.5792 - val_loss: 0.9025 - val_accuracy: 0.5791\n",
      "Epoch 88/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9011 - accuracy: 0.5796 - val_loss: 0.9018 - val_accuracy: 0.5793\n",
      "Epoch 89/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.9004 - accuracy: 0.5802 - val_loss: 0.9012 - val_accuracy: 0.5797\n",
      "Epoch 90/100\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.8998 - accuracy: 0.5807 - val_loss: 0.9007 - val_accuracy: 0.5802\n",
      "Epoch 91/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.8991 - accuracy: 0.5812 - val_loss: 0.9000 - val_accuracy: 0.5809\n",
      "Epoch 92/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.8985 - accuracy: 0.5815 - val_loss: 0.8994 - val_accuracy: 0.5813\n",
      "Epoch 93/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.8978 - accuracy: 0.5820 - val_loss: 0.8988 - val_accuracy: 0.5817\n",
      "Epoch 94/100\n",
      "1717/1717 [==============================] - 8s 5ms/step - loss: 0.8972 - accuracy: 0.5823 - val_loss: 0.8982 - val_accuracy: 0.5824\n",
      "Epoch 95/100\n",
      "1717/1717 [==============================] - 7s 4ms/step - loss: 0.8965 - accuracy: 0.5829 - val_loss: 0.8976 - val_accuracy: 0.5826\n",
      "Epoch 96/100\n",
      "1717/1717 [==============================] - 7s 4ms/step - loss: 0.8959 - accuracy: 0.5832 - val_loss: 0.8969 - val_accuracy: 0.5834\n",
      "Epoch 97/100\n",
      "1717/1717 [==============================] - 7s 4ms/step - loss: 0.8953 - accuracy: 0.5838 - val_loss: 0.8963 - val_accuracy: 0.5839\n",
      "Epoch 98/100\n",
      "1717/1717 [==============================] - 7s 4ms/step - loss: 0.8946 - accuracy: 0.5843 - val_loss: 0.8958 - val_accuracy: 0.5841\n",
      "Epoch 99/100\n",
      "1717/1717 [==============================] - 7s 4ms/step - loss: 0.8940 - accuracy: 0.5847 - val_loss: 0.8952 - val_accuracy: 0.5845\n",
      "Epoch 100/100\n",
      "1717/1717 [==============================] - 7s 4ms/step - loss: 0.8934 - accuracy: 0.5850 - val_loss: 0.8946 - val_accuracy: 0.5849\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([np.array(sentence_embs), np.array(sentence_embs_hyp)],enc_gold_label,epochs = 100,batch_size=256,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
      "[281, 668, 779, 600, 12, 3, 2084, 42, 184, 1455, 2085, 2086, 64, 3, 272, 17, 1, 668]\n",
      "the max sentence length is: 54\n",
      "4093\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    1   10    9    1   43 1400   22   16    4    1  218\n",
      "  282 2087]\n",
      "The church has cracks in the ceiling.\n",
      "[2, 655, 36, 2754, 6, 2, 2755]\n",
      "the max sentence length is: 29\n",
      "5166\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   2   8   3 338 258]\n",
      "[array(['contradiction', 'entailment', 'neutral'], dtype=object)]\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pad_seq_prem_test, embedding_matrix_prem_test, vocab_size_prem_test = get_embedding_matrix(test_df['premise'], embeddings_dict)\n",
    "pad_seq_hyp_test, embedding_matrix_hyp_test, vocab_size_hyp_test = get_embedding_matrix(test_df['hypothesis'], embeddings_dict)\n",
    "\n",
    "sentence_embs_prem_test = baseline_sum_sentence_embeddings(pad_seq_prem_test, embedding_matrix_prem_test)\n",
    "sentence_embs_hyp_test = baseline_sum_sentence_embeddings(pad_seq_hyp_test, embedding_matrix_hyp_test)\n",
    "\n",
    "enc_gold_label_test = encode_labels(test_df['gold_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8877 - accuracy: 0.5857\n",
      "test loss, test acc: [0.8876674771308899, 0.5857084393501282]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using evaluate\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate([sentence_embs_prem_test, sentence_embs_hyp_test], enc_gold_label_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for 3 samples\n",
      "predictions shape: (9824, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict([sentence_embs_prem_test, sentence_embs_hyp_test])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.669341   0.09758869 0.23307024]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[2])\n",
    "# order: contradiction, entailment, neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This church choir sings to the masses as they sing joyous songs from the book at a church. A choir singing at a baseball game. contradiction\n"
     ]
    }
   ],
   "source": [
    "print(test_df['premise'][2], test_df['hypothesis'][2], test_df['gold_label'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
