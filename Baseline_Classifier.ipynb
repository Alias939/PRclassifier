{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "\n",
    "# define path to glove and snli files\n",
    "path = \"../Project/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\Anaconda3\\envs\\gameAI\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Danie\\Anaconda3\\envs\\gameAI\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\Users\\Danie\\Anaconda3\\envs\\gameAI\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "snli_train = pd.read_csv(path+'snli_1.0/snli_1.0_train.txt', sep=\"\\\\t\")\n",
    "snli_test = pd.read_csv(path+'snli_1.0/snli_1.0_test.txt', sep=\"\\\\t\")\n",
    "snli_dev = pd.read_csv(path+'snli_1.0/snli_1.0_dev.txt', sep=\"\\\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane. A person is training his horse for a competition. neutral\n",
      "A person on a horse jumps over a broken down airplane. A person is at a diner, ordering an omelette. contradiction\n",
      "A person on a horse jumps over a broken down airplane. A person is outdoors, on a horse. entailment\n"
     ]
    }
   ],
   "source": [
    "print(snli_train['sentence1'][0],snli_train['sentence2'][0], snli_train['gold_label'][0])\n",
    "print(snli_train['sentence1'][1],snli_train['sentence2'][1], snli_train['gold_label'][1])\n",
    "print(snli_train['sentence1'][2],snli_train['sentence2'][2], snli_train['gold_label'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and rename the important columns\n",
    "train_df = snli_train.filter(['sentence1','sentence2','gold_label'], axis=1)\n",
    "test_df = snli_test.filter(['sentence1','sentence2','gold_label'], axis=1)\n",
    "train_df = train_df.rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})\n",
    "test_df = test_df.rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude sentences which could not be categorised\n",
    "train_df = train_df[train_df['gold_label'] != \"-\"]\n",
    "test_df = test_df[test_df['gold_label'] != \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       3368\n",
       "contradiction    3237\n",
       "neutral          3219\n",
       "Name: gold_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['gold_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(path+\"glove.6B.300d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queen', 'monarch', 'prince', 'kingdom']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))\n",
    "find_closest_embeddings(embeddings_dict[\"king\"])[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following guide https://medium.com/@sarin.samarth07/glove-word-embeddings-with-keras-python-code-52131b0c8b1d\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Input, Add, Dot, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.sequence import skipgrams\n",
    "from tensorflow.python.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(series):\n",
    "    series = series.astype(str)\n",
    "\n",
    "    token = Tokenizer()\n",
    "    token.fit_on_texts(series)\n",
    "    seq = token.texts_to_sequences(series)\n",
    "\n",
    "    print(series[0])\n",
    "    print(seq[0])\n",
    "\n",
    "    print(\"the max sentence length is:\",max([len(x) for x in seq]))\n",
    "    pad_seq = pad_sequences(seq,maxlen=100)\n",
    "    vocab_size = len(token.word_index)+1\n",
    "    print(vocab_size)\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size,300))\n",
    "    for word,i in token.word_index.items():\n",
    "        embedding_value = embeddings_dict.get(word) #using glove embedding for each word\n",
    "        if embedding_value is not None:\n",
    "            embedding_matrix[i] = embedding_value\n",
    "\n",
    "    # Sum embeddings of words together to get embedding of sentence (baseline sentence embedding model)\n",
    "    print(pad_seq[4])\n",
    "    return pad_seq, embedding_matrix, vocab_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane.\n",
      "[1, 56, 5, 1, 197, 191, 68, 1, 1762, 36, 877]\n",
      "the max sentence length is: 78\n",
      "18490\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  59 132   4 666  16  94]\n"
     ]
    }
   ],
   "source": [
    "pad_seq_prem, embedding_matrix_prem, vocab_size_prem = get_embedding_matrix(train_df['premise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person is training his horse for a competition.\n",
      "[1, 27, 3, 821, 16, 162, 20, 1, 275]\n",
      "the max sentence length is: 56\n",
      "30904\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  22   4  40 705]\n"
     ]
    }
   ],
   "source": [
    "pad_seq_hyp, embedding_matrix_hyp, vocab_size_hyp = get_embedding_matrix(train_df['hypothesis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "### Sum embeddings of all words in a sentence together to get the complete embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_sum_sentence_embeddings(pad_seq, embedding_matrix):\n",
    "    # Sum embeddings of words together to get embedding of sentence (baseline sentence embedding model)\n",
    "    sentence_embs = []\n",
    "    for i in pad_seq:\n",
    "        sentence_embs.append(sum([embedding_matrix[x] for x in i]))\n",
    "    sentence_embs = np.array(sentence_embs)\n",
    "    return sentence_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embs = baseline_sum_sentence_embeddings(pad_seq_prem, embedding_matrix_prem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embs_hyp = baseline_sum_sentence_embeddings(pad_seq_hyp, embedding_matrix_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          30100       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          30100       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200)          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          60300       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          90300       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          90300       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 300)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3)            903         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 302,003\n",
      "Trainable params: 302,003\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import datasets, layers, models\n",
    "\n",
    "\n",
    "#model\n",
    "# shape represents 300d glove embedding of sentence \n",
    "shape=(300)\n",
    "\n",
    "premise= layers.Input(shape=shape)\n",
    "hypothesis= layers.Input(shape=shape)\n",
    "\n",
    "xp=layers.Dense(100,activation='tanh')(premise)\n",
    "xh=layers.Dense(100,activation='tanh')(hypothesis)\n",
    "\n",
    "conc=layers.concatenate([xp,xh])\n",
    "\n",
    "y= layers.Dense(300,activation='tanh')(conc)\n",
    "y= layers.Dense(300,activation='tanh')(y)\n",
    "y= layers.Dense(300,activation='tanh')(y)\n",
    "\n",
    "output=layers.Flatten()(y)\n",
    "output = layers.Dense(3, activation='softmax')(output)\n",
    "\n",
    "model = keras.models.Model([premise,hypothesis], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta',loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def encode_labels(gold_label):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(np.array(gold_label).reshape(-1, 1))\n",
    "\n",
    "    print(enc.categories_)\n",
    "\n",
    "    enc_gold_label = enc.transform(np.array(gold_label).reshape(-1, 1)).toarray()\n",
    "\n",
    "    print(enc_gold_label[2])\n",
    "    return enc_gold_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['contradiction', 'entailment', 'neutral'], dtype=object)]\n",
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "enc_gold_label = encode_labels(train_df['gold_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 1.1345 - accuracy: 0.3496 - val_loss: 1.0900 - val_accuracy: 0.3902\n",
      "Epoch 2/40\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 1.0837 - accuracy: 0.4028 - val_loss: 1.0656 - val_accuracy: 0.4310\n",
      "Epoch 3/40\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 1.0620 - accuracy: 0.4379 - val_loss: 1.0496 - val_accuracy: 0.4561\n",
      "Epoch 4/40\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 1.0471 - accuracy: 0.4585 - val_loss: 1.0383 - val_accuracy: 0.4708\n",
      "Epoch 5/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.0340 - accuracy: 0.4740 - val_loss: 1.0292 - val_accuracy: 0.4804\n",
      "Epoch 6/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.0274 - accuracy: 0.4802 - val_loss: 1.0221 - val_accuracy: 0.4884\n",
      "Epoch 7/40\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 1.0200 - accuracy: 0.4872 - val_loss: 1.0162 - val_accuracy: 0.4934\n",
      "Epoch 8/40\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 1.0158 - accuracy: 0.4916 - val_loss: 1.0112 - val_accuracy: 0.4986\n",
      "Epoch 9/40\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 1.0095 - accuracy: 0.4976 - val_loss: 1.0067 - val_accuracy: 0.5025\n",
      "Epoch 10/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.0048 - accuracy: 0.5020 - val_loss: 1.0027 - val_accuracy: 0.5064\n",
      "Epoch 11/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.0024 - accuracy: 0.5033 - val_loss: 0.9991 - val_accuracy: 0.5092\n",
      "Epoch 12/40\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.9979 - accuracy: 0.5063 - val_loss: 0.9959 - val_accuracy: 0.5118\n",
      "Epoch 13/40\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.9946 - accuracy: 0.5100 - val_loss: 0.9928 - val_accuracy: 0.5147\n",
      "Epoch 14/40\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.9916 - accuracy: 0.5124 - val_loss: 0.9901 - val_accuracy: 0.5170\n",
      "Epoch 15/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9901 - accuracy: 0.5131 - val_loss: 0.9875 - val_accuracy: 0.5194\n",
      "Epoch 16/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9856 - accuracy: 0.5181 - val_loss: 0.9851 - val_accuracy: 0.5213\n",
      "Epoch 17/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9832 - accuracy: 0.5196 - val_loss: 0.9827 - val_accuracy: 0.5227\n",
      "Epoch 18/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9800 - accuracy: 0.5222 - val_loss: 0.9806 - val_accuracy: 0.5239\n",
      "Epoch 19/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9790 - accuracy: 0.5235 - val_loss: 0.9785 - val_accuracy: 0.5262\n",
      "Epoch 20/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9755 - accuracy: 0.5265 - val_loss: 0.9765 - val_accuracy: 0.5274\n",
      "Epoch 21/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9756 - accuracy: 0.5250 - val_loss: 0.9747 - val_accuracy: 0.5281\n",
      "Epoch 22/40\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.9732 - accuracy: 0.5277 - val_loss: 0.9729 - val_accuracy: 0.5288\n",
      "Epoch 23/40\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.9711 - accuracy: 0.5293 - val_loss: 0.9713 - val_accuracy: 0.5297\n",
      "Epoch 24/40\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.9676 - accuracy: 0.5319 - val_loss: 0.9695 - val_accuracy: 0.5311\n",
      "Epoch 25/40\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.9677 - accuracy: 0.5322 - val_loss: 0.9679 - val_accuracy: 0.5323\n",
      "Epoch 26/40\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.9662 - accuracy: 0.5333 - val_loss: 0.9664 - val_accuracy: 0.5333\n",
      "Epoch 27/40\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.9623 - accuracy: 0.5363 - val_loss: 0.9650 - val_accuracy: 0.5342\n",
      "Epoch 28/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9613 - accuracy: 0.5365 - val_loss: 0.9636 - val_accuracy: 0.5349\n",
      "Epoch 29/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9627 - accuracy: 0.5348 - val_loss: 0.9622 - val_accuracy: 0.5367\n",
      "Epoch 30/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9607 - accuracy: 0.5367 - val_loss: 0.9610 - val_accuracy: 0.5365\n",
      "Epoch 31/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9598 - accuracy: 0.5384 - val_loss: 0.9596 - val_accuracy: 0.5380\n",
      "Epoch 32/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9569 - accuracy: 0.5395 - val_loss: 0.9584 - val_accuracy: 0.5383\n",
      "Epoch 33/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9549 - accuracy: 0.5413 - val_loss: 0.9572 - val_accuracy: 0.5393\n",
      "Epoch 34/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9542 - accuracy: 0.5411 - val_loss: 0.9560 - val_accuracy: 0.5411\n",
      "Epoch 35/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9527 - accuracy: 0.5424 - val_loss: 0.9550 - val_accuracy: 0.5419\n",
      "Epoch 36/40\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.9522 - accuracy: 0.5432 - val_loss: 0.9539 - val_accuracy: 0.5427\n",
      "Epoch 37/40\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.9502 - accuracy: 0.5433 - val_loss: 0.9528 - val_accuracy: 0.5433\n",
      "Epoch 38/40\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.9501 - accuracy: 0.5444 - val_loss: 0.9517 - val_accuracy: 0.5442\n",
      "Epoch 39/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9464 - accuracy: 0.5476 - val_loss: 0.9508 - val_accuracy: 0.5440\n",
      "Epoch 40/40\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.9475 - accuracy: 0.5472 - val_loss: 0.9497 - val_accuracy: 0.5451\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([np.array(sentence_embs[0:300000]), np.array(sentence_embs_hyp[0:300000])],enc_gold_label[0:300000],epochs = 40,batch_size=256,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: baseline_300000_40epochs\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('baseline_300000_40epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
      "[281, 668, 779, 600, 12, 3, 2084, 42, 184, 1455, 2085, 2086, 64, 3, 272, 17, 1, 668]\n",
      "the max sentence length is: 54\n",
      "4093\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    1   10    9    1   43 1400   22   16    4    1  218\n",
      "  282 2087]\n",
      "The church has cracks in the ceiling.\n",
      "[2, 655, 36, 2754, 6, 2, 2755]\n",
      "the max sentence length is: 29\n",
      "5166\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   2   8   3 338 258]\n",
      "[array(['contradiction', 'entailment', 'neutral'], dtype=object)]\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pad_seq_prem_test, embedding_matrix_prem_test, vocab_size_prem_test = get_embedding_matrix(test_df['premise'])\n",
    "pad_seq_hyp_test, embedding_matrix_hyp_test, vocab_size_hyp_test = get_embedding_matrix(test_df['hypothesis'])\n",
    "\n",
    "sentence_embs_prem_test = baseline_sum_sentence_embeddings(pad_seq_prem_test, embedding_matrix_prem_test)\n",
    "sentence_embs_hyp_test = baseline_sum_sentence_embeddings(pad_seq_hyp_test, embedding_matrix_hyp_test)\n",
    "\n",
    "enc_gold_label_test = encode_labels(test_df['gold_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.9396 - accuracy: 0.55 - 0s 3ms/step - loss: 0.9368 - accuracy: 0.5545\n",
      "test loss, test acc: [0.9368278384208679, 0.5544584393501282]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate([sentence_embs_prem_test, sentence_embs_hyp_test], enc_gold_label_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for 3 samples\n",
      "predictions shape: (9824, 3)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict([sentence_embs_prem_test, sentence_embs_hyp_test])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(history.history).to_csv('baseline_history_300000_40epochs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_baseline = pd.DataFrame(predictions)\n",
    "test_results_baseline.to_csv(\"Baseline_test_results_300000_40epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2aca4e18988>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
